diff --git a/README.md b/README.md
index a8f071b..66fa2c2 100644
--- a/README.md
+++ b/README.md
@@ -567,3 +567,7 @@ you have trained your new model on the new data.
 ## License
 
 [License](LICENSE.txt)
+
+/Users/zhas/anaconda3/envs/nyc_airbnb_dev/bin/mlflow
+/Users/zhas/anaconda3/envs/nyc_airbnb_dev/bin/wandb
+/Users/zhas/anaconda3/envs/nyc_airbnb_dev/bin/jupyter notebook
diff --git a/components/wandb_utils/log_artifact.py b/components/wandb_utils/log_artifact.py
index c242c60..67275de 100644
--- a/components/wandb_utils/log_artifact.py
+++ b/components/wandb_utils/log_artifact.py
@@ -1,6 +1,4 @@
 import wandb
-import mlflow
-
 
 def log_artifact(artifact_name, artifact_type, artifact_description, filename, wandb_run):
     """
diff --git a/main.py b/main.py
index 9abc5bb..dd7a227 100644
--- a/main.py
+++ b/main.py
@@ -28,6 +28,9 @@ def go(config: DictConfig):
     os.environ["WANDB_PROJECT"] = config["main"]["project_name"]
     os.environ["WANDB_RUN_GROUP"] = config["main"]["experiment_name"]
 
+    # You can get the path at the root of the MLflow project with this:
+    root_path = hydra.utils.get_original_cwd()
+
     # Steps to execute
     steps_par = config['main']['steps']
     active_steps = steps_par.split(",") if steps_par != "all" else _steps
@@ -52,19 +55,46 @@ def go(config: DictConfig):
             ##################
             # Implement here #
             ##################
-            pass
+            _ = mlflow.run(
+                os.path.join(root_path, "basic_cleaning"),
+                "main",
+                parameters={
+                    "input_artifact": "sample.csv:latest",
+                    "artifact_name": "preprocessed_data.csv",
+                    "artifact_type": "preprocessed_data",
+                    "artifact_description": "Basic data cleaning applied"
+                },
+            )
 
         if "data_check" in active_steps:
             ##################
             # Implement here #
             ##################
-            pass
+            _ = mlflow.run(
+                os.path.join(root_path, "data_check"),
+                "main",
+                parameters={
+                    "reference_artifact": config["data"]["reference_dataset"],
+                    "sample_artifact": "preprocessed_data.csv:latest",
+                    "ks_alpha": config["data"]["ks_alpha"]
+                },
+            )
 
         if "data_split" in active_steps:
             ##################
             # Implement here #
             ##################
-            pass
+            _ = mlflow.run(
+                os.path.join(root_path, "data_split"),
+                "main",
+                parameters={
+                    "input_artifact": "preprocessed_data.csv:latest",
+                    "artifact_root": "data",
+                    "artifact_type": "segregated_data",
+                    "test_size": config["data"]["test_size"],
+                    "stratify": config["data"]["stratify"]
+                },
+            )
 
         if "train_random_forest" in active_steps:
 
@@ -80,7 +110,18 @@ def go(config: DictConfig):
             # Implement here #
             ##################
 
-            pass
+            _ = mlflow.run(
+                os.path.join(root_path, "train_random_forest"),
+                "main",
+                parameters={
+                    "train_data": "data_train.csv:latest",
+                    "model_config": rf_config,
+                    "export_artifact": config["random_forest_pipeline"]["export_artifact"],
+                    "random_seed": config["main"]["random_seed"],
+                    "val_size": config["data"]["test_size"],
+                    "stratify": config["data"]["stratify"]
+                },
+            )
 
         if "test_regression_model" in active_steps:
 
@@ -88,7 +129,14 @@ def go(config: DictConfig):
             # Implement here #
             ##################
 
-            pass
+             _ = mlflow.run(
+                f"{config['main']['components_repository']}/test_regression_model",
+                "main",
+                parameters={
+                    "model_export": f"{config['random_forest_pipeline']['export_artifact']}:latest",
+                    "test_data": "data_test.csv:latest"
+                },
+            )
 
 
 if __name__ == "__main__":
